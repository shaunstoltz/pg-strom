@ja{
本章では、PL/CUDA言語を用いて、GPUで実行可能なネイティブプログラムをSQL関数として実装する方法について説明します。
}
@en{
This chapter introduces the way to implement GPU executable native program as SQL functions, using PL/CUDA procedural language.
}

@ja:# PL/CUDA概要
@en:# PL/CUDA Overview

@ja{
内部的に、PG-StromはSQL構文を元にCUDA言語によるGPUプログラムを生成し、これを実行時コンパイルによってGPU用命令バイナリを生成します。 CUDAとはNVIDIA社の提供するプログラミング環境で、C言語に似た構文を用いてGPUで並列実行可能なプログラムを記述する事ができます。 SQL構文からCUDAプログラムへの変換プロセスは内部的なもので、ユーザの視点からは、どのようなGPU用プラグラムが生成、実行されるのかを意識する必要はありません。

一方、PostgreSQLでは`CREATE LANGUAGE`構文を用いてSQL関数の記述に用いるプログラミング言語を追加する事ができます。 PL/CUDAとは`CREATE LANGUAGE`構文に対応した言語ハンドラで、SQLを元にPG-Stromが自動生成するGPUプログラムだけでなく、ユーザが実装した任意のGPUプログラムをSQL関数として実行する事が可能となります。

SQL関数の引数には、数値型や文字列型、行列型など、PG-Stromのサポートするデータ型を使用する事ができますが、これらはPL/CUDA実行系が自動的にGPU側へデータを転送するため、データベースとGPU間のデータロードについて意識する必要はありません。また同様に、PL/CUDA関数の戻り値（可変長データ型である場合を含む）もGPU側からCPU側へと書き戻され、SQL関数の戻り値として整形されます。

また、PL/CUDA関数の引数としてgstore_fdwを用いて定義した外部表を使用する事ができます。この場合、データは既にGPUにロード済みであるためPL/CUDA関数呼び出しのたびにデータロードを行う必要はなく、またPostgreSQL可変長データの長さ制限である1GBよりも大きなデータを使用する事ができます。

これらの特徴により、ユーザはGPUやデータベースとの間のデータの入出力といった定型的な処理に煩わされる事なく、統計解析ロジックの実装や高速化といった生産的な作業に注力する事ができます。
}

@en{
PG-Strom internally constructs GPU programs by CUDA language, according to the supplied SQL, then generates GPU's native binary using just-in-time compile. CUDA is a programming environment provided by NVIDIA. It allows implementing parallel program which is executable on GPU device, using C-like statement. This transformation process from SQL statement to CUDA program is an internal process, thus, no need to pay attention what GPU programs are generated and executed from the standpoint of users.

On the other hands, PostgreSQL supports to add programming language to implement SQL functions by `CREATE LANGUAGE` statement. PL/CUDA is a language handler to supports `CREATE LANGUAGE` command. It also allows users to run arbitrary GPU programs manually implemented as SQL functions, but not only GPU programs automatically generated by PG-Strom based on SQL.

Its argument can take the data types supported by PG-Strom, like numeric, text, or array-matrix data type. These arguments are implicitly loaded onto GPU device memory by the PL/CUDA infrastructure, so users don't need to pay attention for data loading between the database and GPU devices. In a similar fashion, the return value of PL/CUDA function (including the case of variable length data type) will be written back to CPU from GPU, then decode to the result of SQL function.

You can also use foreign tables defined with `gstore_fdw` as arguments of PL/CUDA function. In this case, no need to load the data onto GPU for each invocation because foreign table already keeps the data, and available to use larger data than 1GB which is a restriction of variable length data in PostgreSQL.

Therefore, users can focus on productive tasks like implementation of statistical analysis, code optimization and so on, without routine process like data input/output between GPU and databases.
}

![PL/CUDA Overview](./img/plcuda-overview.png)

@ja{
`CREATE FUNCTION`構文を用いてPL/CUDA関数を定義すると、この関数の定義部を含むCUDAプログラムのソースコードを作成し、これをターゲットGPU向けにビルドします。
このCUDAプログラムは、引数の受け渡しと結果を返却するための補助的なコードを含む以外は、一般的なCUDAランタイムを用いたソフトウェアと全く同一で、CUDAの提供する各種のライブラリをインクルード／リンクする事も可能です。
}
@en{
Once a PL/CUDA function is declared using `CREATE FUNCTION`, it generates a CUDA program source code that embeds the definition of this function, then build it for the target GPU device.
This CUDA program is almost identical to usual GPU software based on CUDA runtime, except for the auxiliary code to receive arguments of SQL function and to write back its results. It also allows to include/link some libraries for CUDA device runtime.
}
@ja{
PL/CUDA関数を用いて作成したネイティブのCUDAプログラムは、PostgreSQLバックエンドの子プロセスとして実行されます。
したがって、PostgreSQLとは独立したアドレス空間と、OSやGPUのリソースを持つ事になります。
CUDAプログラムには、ホストシステム上で実行されるホストコードと、GPU上で実行されるデバイスコードを含みます。ホストコードはC言語でプログラミング可能なあらゆるロジックを実行可能ですので、セキュリティ上の観点から、PL/CUDA関数の定義はデータベース特権ユーザに限定されています。
}
@en{
Native CUDA programs implemented by PL/CUDA are executed as child-processes of PostgreSQL backend.
Therefore, it has independent address space and OS/GPU resources from PostgreSQL.
CUDA program contains host code for the host system and device code to be executed on GPU devices.
The host code can execute any logic we can program using C-language, so we restrict only database superuser can define PL/CUDA function from the standpoint of security.
}
@ja{
以下に単純なPL/CUDA関数の例を示します。 この関数は、同じ長さの`read`型配列を二つ引数に取り、そのドット積を`float`型で返却します。
}
@en{
Below is an example of simple PL/CUDA function. This function takes two same length `real[]` array as arguments, then returns its dot product in `float` data type.
}
```
CREATE OR REPLACE FUNCTION
gpu_dot_product(real[], real[])
RETURNS float
AS $$
#plcuda_decl
#include "cuda_matrix.h"

KERNEL_FUNCTION_MAXTHREADS(void)
gpu_dot_product(double *p_dot,
                VectorTypeFloat *X,
                VectorTypeFloat *Y)
{
    size_t      index = get_global_id();
    size_t      nitems = X->height;
    float       v[MAXTHREADS_PER_BLOCK];
    float       sum;

    if (index < nitems)
        v[get_local_id()] = X->values[index] * Y->values[index];
    else
        v[get_local_id()] = 0.0;

    sum = pgstromTotalSum(v, MAXTHREADS_PER_BLOCK);
    if (get_local_id() == 0)
        atomicAdd(p_dot, (double)sum);
    __syncthreads();
}
#plcuda_begin
{
    size_t      nitems;
    int         blockSz;
    int         gridSz;
    double     *dot;
    cudaError_t rc;

    if (!VALIDATE_ARRAY_VECTOR_TYPE_STRICT(arg1, PG_FLOAT4OID) ||
        !VALIDATE_ARRAY_VECTOR_TYPE_STRICT(arg2, PG_FLOAT4OID))
        EEXIT("arguments are not vector like array");
    nitems = ARRAY_VECTOR_HEIGHT(arg1);
    if (nitems != ARRAY_VECTOR_HEIGHT(arg2))
        EEXIT("length of arguments mismatch");

    rc = cudaMallocManaged(&dot, sizeof(double));
    if (rc != cudaSuccess)
        CUEXIT(rc, "failed on cudaMallocManaged");
    memset(dot, 0, sizeof(double));

    blockSz = MAXTHREADS_PER_BLOCK;
    gridSz = (nitems + MAXTHREADS_PER_BLOCK - 1) / MAXTHREADS_PER_BLOCK;
    gpu_dot_product<<<gridSz,blockSz>>>(dot,
                                        (VectorTypeFloat *)arg1,
                                        (VectorTypeFloat *)arg2);
    rc = cudaStreamSynchronize(NULL);
    if (rc != cudaSuccess)
        CUEXIT(rc, "failed on cudaStreamSynchronize");

    return *dot;
}
#plcuda_end
$$ LANGUAGE 'plcuda';
```

@ja{
PL/CUDA実行系は、`#plcuda_begin`と`#plcuda_end`で囲まれた部分にSQL関数の引数の受け渡しを行う処理を付加して、CUDAプログラムのエントリポイントを作成します。
`#plcuda_decl`と`#plcuda_begin`で囲まれた部分は、GPUデバイス関数やその他のホスト関数を宣言するためのブロックで、ソースコード上では上記のエントリポイントより前に配置されます。
}
@en{
PL/CUDA infrastructure makes entrypoint function of CUDA program by the block between `#plcuda_begin` and `#plcuda_end` with extra code to exchange arguments of SQL function.
The portion enclosed by `#plcuda_decl` and `#plcuda_begin` is a block for declaration of GPU device functions and other host functions. It is placed prior to the entrypoint above.
}
@ja{
CUDAプログラムのエントリポイントでは、`arg1`、`arg2`、... という形でSQL関数の引数を参照する事ができます。

上記の例では、`real[]`配列型である`arg1`および`arg2`がエントリポイントへ渡され、`VALIDATE_ARRAY_VECTOR_TYPE_STRICT`マクロによってNULLを含まない32bit浮動小数点型の１次元配列であるかどうかを検証しています。

返り値も同様に、SQLデータ型に相当するCUDA Cデータ型をエントリポイントから返します。
エントリポイントが`return`で値を返さない場合（または明示的に`exit()`で終了コード1を返した場合）、PL/CUDA関数は`NULL`値を返却したものとして扱われます。
}
@en{
At the entrypoint of the CUDA program, you can refer the arguments of SQL function using `arg1`, `arg2, and so on.

In the above example, the `arg1` and `arg2`, `real[]` array type, are passed to the entrypoint, then `VALIDATE_ARRAY_VECTOR_TYPE_STRICT` macro checks whether it is 1-dimensional array of 32bit floating-point values without NULL.

Ditto with return value, the entrypoint returns a value in CUDA C representation corresponding to the SQL data type.
If entrypoint does not return any value (or, it exits the program with status code 1 by `exit()`), it is considered PL/CUDA function returns `NULL`. 
}

@ja{
上記のサンプルプログラムでは、SQL関数から受け取った`real`型配列を検証した後、`cudaMallocManaged`で結果バッファを獲得した後、GPUカーネル関数である`gpu_dot_product`を呼出してドット積を計算しています。
}
@en{
The above sample program validates the array of `real` values passed from SQL function, then it allocates the result buffer by `cudaMallocManaged`, and invokes `gpu_dot_product`, a GPU kernel function, to compute dot product with two vectors.
}

@ja{
この関数の実行結果は以下の通りです。ランダムに生成した10,000個の要素を持つベクトル同士の内積を計算しています。
}
@en{
The result of this function is below. It computes the dot product of two vectors which contain 10,000 items randomly generated.
}

```
postgres=# SELECT gpu_dot_product(array_matrix(random()::real),
                                  array_matrix(random()::real))
             FROM generate_series(1,10000);
 gpu_dot_product
------------------
 3.71461999509484
(1 row)
```

@ja:# PL/CUDAの構造
@en:# PL/CUDA Structure

@ja{
PL/CUDAの関数定義は、`#plcuda_decl`、`#plcuda_begin`、および`#plcuda_end`の各ディレクティブによって分割されたコードブロックから構成されます。各コードブロックには各々の目的に応じたユーザ定義のCUDA Cコードを記述する事ができ、これらは、PL/CUDA言語ハンドラとの引数及び結果の受け渡しを行うロジックと結合し一個のソースファイルへと再構成されます。
}
@en{
Function declaration of PL/CUDA is consists of two code blocks split by the directives of `#plcuda_decl`, `#plcuda_begin` and `#plcuda_end`. Users can put their custom code on the code blocks according to the purpose, then PL/CUDA language handler reconstruct them into single source file with extra logic to exchange function arguments and results.
}
```
#plcuda_decl
  [...any declarations...]
#plcuda_begin
  [...host code in the entrypoint...]
#plcuda_end
```

@ja{
`#plcuda_decl`より始まるコードブロックは、`__host__`および`__device__`属性を持つCUDA C関数や変数を完全な形で記述する事ができます。
このコードブロックは、最終的に構築されるソースファイル上で、`#plcuda_begin`...`#plcuda_end`ブロックを含むエントリポイントよりも前方に位置します。

また、CUDA Cの`#include`構文を用いて外部ヘッダファイルをインクルードする場合には、このコードブロックに記述するようにして下さい。
}
@en{
The code block, begins from `#plcuda_decl`, can have declaration of `__host__` and `__device__` functions and variables for CUDA C.
This code block locates in front of the entrypoint function which contains the code block between `#plcuda_begin` and `#plcuda_end` at the source file eventually constructed.

If external header files are included using `#include` statement of CUDA C, put the statement on this code block.
}

@ja{
`#plcuda_begin`より始まるコードブロックは、ホストコードであるエントリポイント関数の一部として組み込まれます。したがって、関数名や引数の型などを記述する事はできません。
エントリポイント関数は、当該コードブロックに制御が移る前に、パイプを介してSQL関数の引数をPostgreSQLバックエンドから受信し、`arg1`、`arg2`、…という名前で参照できるようセットアップを行います。

これらの変数は、SQLデータ型に応じて以下の表に示すCUDA Cとしての表現を持ちます。

|SQLデータ型            |CUDA Cデータ型|説明                  |
|:---------------------:|:------------:|:--------------------:|
|`reggstore`            |`void *`      |Gstore_fdw外部表のOID |
|`real`                 |`float`       |32bit浮動小数点型     |
|`float`                |`double`      |64bit浮動小数点型     |
|その他のインライン型   |`Datum`       |`int`、`date`など     |
|固定長ポインタ型       |`void *`      |`uuid`など            |
|可変長データ型(varlena)|`varlena *`   |`text`、`real[]`など  |
}

@en{
The code block between `#plcuda_begin` and `#plcuda_end` is embedded to a part of entrypoint function. Therefore, it does not describe function name, arguments definition and so on.
Prior to execution of the code block, the entrypoint function receives arguments of the SQL function from PostgreSQL backend, and set up `arg1`, `arg2`, ... variables for further references.

These variables have the following CUDA C representation according to SQL data types.

|SQL data type                  |CUDA C data type|Examples              |
|:-----------------------------:|:--------------:|:--------------------:|
|`reggstore`                    |`void *`        |OID of Gstore_fdw foreign table|
|`real`                         |`float`         |32bit floating point  |
|`float`                        |`double`        |64bit floating point  |
|Other inline data types        |`Datum`         |`int`, `date`, ...    |
|Fixed-length value by reference|`void *`        |`uuid`, ...           |
|Variable-length value (varlena)|`varlena *`     |`text`, `real[]`, ... |
}

@ja{
PL/CUDA言語ハンドラは、上記のコードブロックから一個のCUDA Cソースファイルを作成し、宣言時または実行時に１度だけ`nvcc`コンパイラでこれをビルドしCUDAプログラムを生成します。
`#plcuda_include`ディレクティブを含む場合はCUDA Cソースファイルが実行時にしか確定しないため、実行時にのみこれをビルドします。ただし、同一内容のCUDAプログラムがビルド済みである場合にはこれを再利用します。
}
@en{
PL/CUDA language handler constructs a single CUDA C source file from the code blocks above, then builds it once by `nvcc` compiler at declaration or execution time.
If it contains any `#plcuda_include` directive, its source code is not fixed until execution time, so built at the execution time only. In case when identical CUDA program is already pre-built, we can reuse it without rebuild.
}
![PL/CUDA Callflow](./img/plcuda-callflow.png)

@ja{
SQLからPL/CUDA関数を呼び出すと、PL/CUDA言語ハンドラはビルド済みのCUDAプログラムを起動し、パイプを通じてSQL関数の引数をコピーします。引数はCUDAプログラム内の引数バッファに格納され、これらは`arg1`や`arg2`などの名前で参照する事が可能です。

可変長データ型などCUDA Cプログラム上でポインタとして表現されるデータ型は、引数バッファへの参照として初期化されます。引数バッファは`cudaMallocManaged()`によって獲得されたmanaged memory領域であるため、当該ポインタはホスト⇔デバイス間の明示的なDMAなしに使用する事ができます。

引数が`reggstore`型を持つ場合は特殊です。これは本来Gstore_Fdw外部テーブルのOID（4バイト整数）を表現するデータ型ですが、PL/CUDAの引数として与えられた場合はGstore_fdwが獲得しているGPUデバイスメモリへの参照へと置き換えられます。
引数は`GstoreIpcMapping`オブジェクトへの参照として初期化され、`GstoreIpcMapping::map`にはGstore_Fdw外部テーブルの確保したGPUデバイスメモリをマップしたアドレスが入ります。
当該領域を物理的に保持しているGPUデバイスIDは`GstoreIpcHandle::device_id`を、当該領域の長さは`GstoreIpcHandle::rawsize`を参照してください。
}
@en{
When SQL command invokes PL/CUDA function, PL/CUDA language handler launch the pre-built CUDA program, then copies the arguments of SQL function over pipe. These are stored in the argument buffer of the CUDA program, so custom logic can refer them using `arg1` or `arg2` variables.

The data types by reference at CUDA C program, like variable-length datum, are initialized as pointers to the argument buffer. It is a managed memory region allocated by `cudaMallocManaged()`, these pointers are available without explicit DMA between host system and GPU devices.

Here is a special case if argument has `reggstore` type. It is actually an OID (32bit integer) of Gstore_Fdw foreign table, however, it is replaced to the reference of GPU device memory acquired by the Gstore_Fdw foreign table if it is supplied as PL/CUDA argument.

The argument is setup to the pointer for `GstoreIpcMapping` object. `GstoreIpcMapping::map` holds the mapped address of the GPU device memory acquired by the Gstore_Fdw foreign table.
`GstoreIpcHandle::device_id` indicates the device-id of GPU which physically holds the region, and GstoreIpcHandle::rawsize` is raw length of the region.
}
```
typedef struct
{
    cl_uint     __vl_len;       /* 4B varlena header */
    cl_short    device_id;      /* GPU device where pinning on */
    cl_char     format;         /* one of GSTORE_FDW_FORMAT__* */
    cl_char     __padding__;    /* reserved */
    cl_long     rawsize;        /* length in bytes */
    union {
#ifdef CU_IPC_HANDLE_SIZE
        CUipcMemHandle      d;  /* CUDA driver API */
#endif
#ifdef CUDA_IPC_HANDLE_SIZE
        cudaIpcMemHandle_t  r;  /* CUDA runtime API */
#endif
        char                data[64];
    } ipc_mhandle;
} GstoreIpcHandle;

typedef struct
{
    GstoreIpcHandle h; /* IPChandle of Gstore_Fdw */
    void       *map;    /* mapped device pointer */
} GstoreIpcMapping;
```

@ja{
PL/CUDA関数の処理結果を返すには、SQLデータ型に対応するCUDA Cのデータをエントリポイントから`return`で返却します。
値を明示的に返却しない場合、CUDA Cでのデータ型がポインタ型であり`NULL`を返した場合、あるいはCUDAプログラムが`exit(1)`によりステータスコード1で終了した場合は、PL/CUDA関数はSQLに対して`null`を返したものとして扱われます。
}
@en{
PL/CUDA function can return its result using `return` of a CUDA C datum relevant to the SQL data type.
In case when no `return` clause is executed, `NULL` pointer is returned if CUDA C data type is pointer, or CUDA program is terminated with status code = 1 by `exit(1)`, PL/CUDA function returns `null` to SQL.
}


@ja:# PL/CUDAリファレンス
@en:# PL/CUDA References

@ja{
本節はPL/CUDA関数のディレクティブ、および関連するSQL関数のリファレンスです。
}
@en{
This section is a reference for PL/CUDA function's directives and related SQL functions.
}

@ja:##PL/CUDAの得意不得意
@en:##Advantage and disadvantage of PL/CUDA

@ja{
PL/CUDA関数が呼び出されると、その背後でCUDAプログラムが起動され、CUDAプログラムはGPUデバイスの初期化を行います。これらの一連の処理は決して軽いものではなく、例えば単純なスカラー値の比較を行うようなロジックをPL/CUDA関数で実装し、10億行のフルテーブルと同時に使用するという使い方は推奨されません。

一方で、ひとたびGPUデバイスの初期化が完了すれば、GPUの持つ数千プロセッサコアを利用して大量データを高速に処理する事が可能です。特に、繰り返し計算により最適パラメータを計算する機械学習や統計解析のように、ワークロードに占める計算の割合が大きな問題に適すると言えるでしょう。
}
@en{
On invocation of PL/CUDA function, it launches the relevant CUDA program on behalf of the invocation, then CUDA program initialize per process context of GPU device. The series of operations are never lightweight, so we don't recommend to implement a simple comparison of scalar values using PL/CUDA, and use for full table scan on billion rows.

On the other hands, once GPU device is correctly initialized, it allows to process massive amount of data using several thousands of processor cores on GPU device. Especially, it is suitable for computing intensive workloads, like machine-learning or advanced analytics that approach to the optimal values by repeated calculation for example.
}

@ja{
処理すべきデータが増加すると、CUDAプログラムとのデータの受け渡し方法にも注意が必要です。
PostgreSQLは配列型をサポートしており、整数型や実数型のデータを高々数百万個程度受け渡すのであれば手軽な方法です。
しかし、配列型を含むPostgreSQLの可変長データの最大長は1GBであるため、これより巨大なデータの受け渡しにはデータの分割など工夫が必要です。また、SQL関数の引数をセットアップするのはPostgreSQLバックエンドプロセスで、この処理はシングルスレッドで動作するためGB単位のメモリ操作には相応の時間を要します。

データサイズが数百MBを越えてきた段階で、Gstore_Fdw外部テーブルの利用を検討してください。
Gstore_Fdwを通して予めGPUデバイスメモリにデータをロードする事で、PL/CUDA関数の呼び出し時に長大な引数をセットアップする必要がなく、また、GPUデバイスメモリ容量が許す限り、GBを越えるサイズのデータを保持する事が可能です。
}

@en{
According to the growth of data size, we need to pay attention how to exchange data with CUDA program.
PostgreSQL supports array types, and it is easy and simple way to exchange several millions of integer or real values at most.

However, variable-length datum of PostgreSQL, including the array-types, is restricted to 1GB at a maximum.
We need to take a little idea to handle larger data, like separation of data-set. In addition, PostgreSQL backend process set up the argument of SQL functions in single thread, so it takes a certain amount of time to manipulate gigabytes-class memory object.

Please consider usage of Gstore_Fdw foreign-table when data size grows more than several hundreds megabytes.
Once you preload the large data-set onto GPU device memory through Gstore_Fdw, no need to set up large arguments on invocation of PL/CUDA function. It also allows to keep larger data than gigabytes, as lond as GPU device memory capacity allows.
}

@ja:##PL/CUDAディレクティブ
@en:##PL/CUDA Directives

### `#plcuda_decl`
@ja{
このディレクティブは`__host__`および`__device__`属性を持つCUDA C関数や変数を含むコードブロックを開始します。PL/CUDA言語ハンドラは、CUDAプログラムのソースファイル上で、このコードブロックをエントリポイントよりも前にそのままコピーします。

このディレクティブの使用は任意ですが、エントリポイントから呼び出すべきGPUカーネル関数を宣言しなければPL/CUDA関数を使用する意味はありませんので、通常は一つ以上のGPUカーネル関数を含む事になります。
}
@en{
This directive begins a code block which contains CUDA C functions and variables with both of `__host__` and `__device__` attributes. PL/CUDA language handler copies this code block in front of the program entrypoint as is.

Use of this directive is optional, however, it makes no sense if here is no declaration of GPU kernel functions to be called from the entrypoint. So, we usually have more than one GPU kernel function.
}

### `#plcuda_begin`
@ja{
このディレクティブは、CUDAプログラムのエントリポイントを構成するコードブロックを開始します。
CUDAプログラムは、受け取ったPL/CUDA関数の引数を`arg1`、`arg2`、...という変数名で参照可能となるよう初期化を行った上で、コードブロックへと制御を移します。当該コードブロックはホストコードであり、CPUで動作する制御ロジックや、GPUカーネルを呼出しての計算処理を記述する事ができます。

結果を返すには、CUDA Cの`return`構文でPL/CUDA関数の返り値に応じたデータを返します。
}
@en{
This directive begins a code block which consists a part of the entrypoint of CUDA program.
The CUDA program setup the referable `arg1`, `arg2`, ... variables according to the arguments of PL/CUDA function, then switch control to the user defined portion. This code block is a host code; we can implement own control logic working on CPU or heavy calculation by GPU kernel invocation.

Result of PL/CUDA function can be returned using `return` statement of CUDA C, according to the function definition.
}

### `#plcuda_end`
@ja{
コードブロックの終了を宣言します。 なお、あるコードブロックの内側で他のコードブロックの開始を宣言した場合、現在のコードブロックは暗黙のうちに`#plcuda_end`ディレクティブによって終了したものとして扱われます。
}
@en{
It marks end of the kernel function code block. By the way, if a directive to start code block was put inside of the different code block, the current code block is implicitly closed by the `#plcuda_end` directive.
}

### `#plcuda_include <function name>`
@ja{
このディレクティブはCUDA Cの`#include`と似ていますが、ヘッダファイルではなく、指定されたSQL関数の実行結果をディレクティブの存在していた場所に挿入します。
オプションで指定するSQL関数はPL/CUDA関数と同一の引数をとり`text`型を返す必要があります。

これは例えば、大量データ間の類似度を計算する際に、計算のアルゴリズムはほとんど同一であるにも関わらず距離計算のロジックだけが異なるバリエーションを動的に作り出す事が可能で、PL/CUDA関数の保守を簡素化する事ができます。
}
@en{
This directive is similar to `#include` of CUDA C, however, it injects result of the specified SQL function onto the location where the directive was written.
The SQL function should have identical arguments and return `text` data.

For example, when we calculate similarity of massive items, we can generate multiple variant of the algorithm on the fly that is almost equivalent but only distance definitions are different. It makes maintenance of PL/CUDA function simplified.
}


### `#plcuda_library <library name>`
@ja{
CUDAプログラムをビルドする際にリンクするライブラリ名を指定します。
`<library name>`に記述するのは、`nvcc`コマンドの`-l`オプションに相当する文字列です。
例えば`libcublas.so`ライブラリをリンクする場合には、接頭語の`lib`と拡張子の`.so`を省略した`cublas`と指定します。
現在のところ、CUDA Toolkitの標準ライブラリパス（`/usr/local/cuda/lib64`）にインストールされたライブラリのみを指定する事ができます。
}
@en{
It specifies the library name to be linked when CUDA program is built by `nvcc`.
The `<library name>` portion is supplied to `nvcc` command as `-l` option.
For example, if `libcublas.co` library is linked, you need to describe `cublas` without prefix (`lib`) and suffix (`.so`).
Right now, we can specify the libraries only installed on the standard library path of CUDA Toolkit (`/usr/local/cuda/lib64).
}

### `#plcuda_sanity_check <function>`
@ja{
GPUカーネルの起動に先立って、引数の妥当性を検証するためのSQL関数をしています。
デフォルトでは妥当性検証関数は設定されていません。
GPUデバイスの初期化などを行う必要があるため、通常、GPUカーネル関数の起動はCPU上で別の関数を起動するよりも重い処理です。もし引数がPL/CUDA関数の仕様からは許容できない値を持っている場合、GPUカーネル関数を実行する数千～数百万（場合によってはそれ以上の）のGPUスレッドは、ただ引数の妥当性をチェックしてエラー状態を返却するためだけに起動されます。GPUカーネル関数を実行する前に、引数の妥当性チェックを十分小さなコストで行えるならば、妥当性検証関数を使用してGPUカーネル関数の実行前にエラーを発生させることを考慮すべきです。 妥当性検証関数は、PL/CUDA関数と同じ型の引数を持ち、`bool`返す関数です。
}
@en{
It allows to specify the sanity check function that preliminary checks adequacy of the supplied arguments, prior to GPU kernel launch.
No sanity check function is configured on the default.
Usually, launch of GPU kernel function is heavier task than call of another function on CPU, because it also involves initialization of GPU devices. If supplied arguments have unacceptable values from the specification of the PL/CUDA function, a few thousands or millions (or more in some cases) of GPU kernel threads shall be launched just to check the arguments and return an error status. If sanity check can be applied prior to the launch of GPU kernel function with enough small cost, it is a valuable idea to raise an error using sanity check function prior to the GPU kernel function. The sanity check function takes identical arguments with PL/CUDA function, and returns `bool` data type.
}

@ja:## PL/CUDA 関連関数
@en:## PL/CUDA Related Functions

@ja{
|関数定義  |結果型|説明|
|:---------|:----:|:---|
|`plcuda_function_source(regproc)`|`text`|引数としてPL/CUDA関数のOIDを与えると、PL/CUDA関数から生成されるGPUカーネルのソースコードを返します。|
}
@en{
|Definition|Result|Description|
|:---------|:----:|:----------|
|`plcuda_function_source(regproc)`|`text`|It returns source code of the GPU kernel generated from the PL/CUDA function, towards the OID input of PL/CUDA function as argument.|
}

@ja:### PL/CUDA関数呼び出し支援
@en:### Support functions for PL/CUDA invocations

@ja{
以下の関数群は、PL/CUDA関数の呼び出しを簡便にするために提供されています。
}
@en{
The functions below are provided to simplify invocation of PL/CUDA functions.
}

@ja{
|関数定義  |結果型|説明|
|:---------|:----:|:---|
|`attnums_of(regclass,text[])`|`smallint[]`|第一引数で指定したテーブルの第二引数で指定した列名（複数可）の列番号を配列として返します。|
|`attnum_of(regclass,text)`|`smallint`|第一引数で指定したテーブルの第二引数で指定した列名の列番号を返します。|
|`atttypes_of(regclass,text[])`|`regtype[]`|第一引数で指定したテーブルの第二引数で指定した列名（複数可）のデータ型を配列として返します。|
|`atttype_of(regclass,text)`|`regtype`|第一引数で指定したテーブルの第二引数で指定した列名のデータ型を返します。|
|`attrs_types_check(regclass,text[],regtype[])`|`bool`|第一引数で指定したテーブルの、第二引数で指定した列名（複数可）のデータ型が、第三引数で指定したデータ型とそれぞれ一致しているかどうかを調べます。|
|`attrs_type_check(regclass,text[],regtype)`|`bool`|第一引数で指定したテーブルの、第二引数で指定した列名（複数可）のデータ型が、全て第三引数で指定したデータ型と一致しているかどうかを調べます。|
}

@en{
|Definition|Result|Description|
|:---------|:----:|:----------|
|`attnums_of(regclass,text[])`|`smallint[]`|It returns attribute numbers for the column names (may be multiple) of the 2nd argument on the table of the 1st argument.|
|`attnum_of(regclass,text)`|`smallint`|It returns attribute number for the column name of the 2nd argument on the table of the 1st argument.|
|`atttypes_of(regclass,text[])`|`regtype[]`|It returns data types for the column names (may be multiple) of the 2nd argument on the table of the 1st argument.|
|`atttype_of(regclass,text)`|`regtype`|It returns data type for the column name of the 2nd argument on the table of the 1st argument.|
|`attrs_types_check(regclass,text[],regtype[])`|`bool`|It checks whether the data types of the columns (may be multiple) of the 2nd argument on the table of the 1st argument match with the data types of the 3rd argument for each.
|`attrs_type_check(regclass,text[],regtype)`|`bool`|It checks whether all the data types of the columns (may be multiple) of the 2nd argument on the table of the 1st argument match with the data type of the 3rd argument.|
}

@ja:### 配列ベースの行列型関数
@en:### Array-Matrix Functions

@ja{
本節ではPG-Stromの提供する配列ベースの行列型をサポートするSQL関数について説明します。

PostgreSQLには行列を表現するための専用のデータ型は存在していませんが、以下の条件を満たす二次元配列をあたかも行列であるかのように取り扱う事が可能です。

- 二次元配列である
- 各次元の配列要素が1から始まる
- NULL値を含まない
- 配列の大きさが1GBを越えない。（PostgreSQL可変長データ表現による制約）
- `smallint`、`int`、`bigint`、`real`または`float`型の配列である

配列がこれらの条件を満たす時、行列の(i,j)要素の位置は添え字から一意に特定する事ができ、GPUスレッドが自らの処理すべきデータを効率的に取り出す事を可能とします。また、通常の行形式データとは異なり、計算に必要なデータのみをロードする事になるため、メモリ消費やデータ転送の点で有利です。 PG-Stromは、この様な疑似的な行列型をサポートするため、以下に示すSQL関数を提供しています。
}
@en{
This section introduces the SQL functions that supports array-based matrix types provided by PG-Strom.

- 2-dimensional Array
- Element of array begins from 1 for each dimension
- No NULL value is contained
- Length of the array is less than 1GB, due to the restriction of variable length datum in PostgreSQL
- Array with `smallint`, `int`, `bigint`, `real` or `float` data type

If and when the array satisfies the above terms, we can determine the location of (i,j) element of the array by the index uniquely, and it enables GPU thread to fetch the datum to be processed very efficiently. Also, array-based matrix packs only the data to be used for calculation, unlike usual row-based format, so it has advantaged on memory consumption and data transfer.
}

@ja{
|関数定義  |結果型|説明|
|:---------|:----:|:---|
|`array_matrix(variadic arg, ...)`|`array`|入力された行を全て連結した配列ベース行列を返す集約関数です。例えば、`float`型の引数x、y、zを1000行入力すると、同じ`float`型で3列×1000行の配列ベース行列を返します。<br>この関数は可変長引数を取るよう定義されており、`arg`は1個以上の`smallint`、`int`、`bigint`、`real`または`float`型のスカラー値で、全ての`arg`値は同じデータ型を持つ必要があります。|
|`matrix_unnest(array)`|`record`|配列ベース行列を行の集合に展開する集合関数です。`array`は`smallint`、`int`、`bigint`、`real`または`float`型の配列で、行列の幅に応じて1個以上のカラムからなる`record`型を返却します。例えば、10列×500行から成る行列の場合、各レコードは行列要素のデータ型を持つ10個のカラムからなり、これが500行生成されます。 <br>標準の`unnest`関数と似ていますが、`record`型を生成するため、`AS (colname1 type[, ...])`句を用いて返却されるべきレコードの型を指定する必要があります。|
|`rbind(array, array)`|`array`|`array`は`smallint`、`int`、`bigint`、`real`または`float`型の配列です。<br>二つの配列ベース行列を縦方向に結合します。双方の行列は同一の要素データ型を持つ必要があり、行列の幅が等しくない場合は足りない部分を0で埋めます。|
|`rbind(array)`|`array`|`array`は`smallint`、`int`、`bigint`、`real`または`float`型の配列です。`rbind(array, array)`と似ていますが、集合関数として動作し入力された全ての配列ベース行列を縦方向に結合します。|
|`cbind(array, array)`|`array`|`array`は`smallint`、`int`、`bigint`、`real`または`float`型の配列で、二つの配列ベース行列を横方向に結合します。双方の行列は同一の要素データ型を持つ必要があり、行列の高さ等しくない場合は足りない部分を0で埋めます。|
|`cbind(array)`|`array`|`array`は`smallint`、`int`、`bigint`、`real`または`float`型の配列で、`cbind(array, array)`と似ていますが、集合関数として動作し入力された全ての配列ベース行列を横方向に結合します。|
|`transpose(array)`|`array`|`array`は`smallint`、`int`、`bigint`、`real`または`float`型の配列で、行列の幅と高さが入れ替わった転置行列を生成します。|
|`array_matrix_validation(anyarray)`|`bool`|入力された配列（`anyarray`）が、配列ベース行列として妥当かどうかを検査します。 PL/CUDA関数実行前の引数の妥当性検証や、DOMAIN型を定義する時の検査制約としての利用を想定しています。|
|`array_matrix_height(array)`|`int`|`array`は`smallint`、`int`、`bigint`、`real`または`float`型の配列で、配列ベース行列の高さを返却します。|
|`array_matrix_width(array)`|`int`|`array`は`smallint`、`int`、`bigint`、`real`または`float`型の配列で、配列ベース行列の幅を返却します。|
}

@en{
|Definition|Result|Description|
|:---------|:----:|:----------|
|`array_matrix(variadic arg, ...)`|`array`|It is an aggregate function that combines all the rows supplied. For example, when 3 `float` arguments were supplied by 1000 rows, it returns an array-based matrix of 3 columns X 1000 rows, with `float` data type.<br>This function is declared to take variable length arguments. The `arg` takes one or more scalar values of either `smallint`, `int`, `bigint`, `real` or `float`. All the arg must have same data types.|
|`matrix_unnest(array)`|`record`|It is a set function that extracts the array-based matrix to set of records. `array` is an array of `smallint`, `int`, `bigint`, `real` or `float` data. It returns `record` type which consists of more than one columns according to the width of matrix. For example, in case of a matrix of 10 columns X 500 rows, each records contains 10 columns with element type of the matrix, then it generates 500 of the records. <br>It is similar to the standard `unnest` function, but generates `record` type, thus, it requires to specify the record type to be returned using `AS (colname1 type[, ...])` clause.|
|`rbind(array, array)`|`array`|`array` is an array of `smallint`, `int`, `bigint`, `real` or `float` data. This function combines the supplied two matrices vertically. Both matrices needs to have same element data type. If width of matrices are not equivalent, it fills up the padding area by zero.|
|`rbind(array)`|`array`|`array` is an array of `smallint`, `int`, `bigint`, `real` or `float` data. This function is similar to `rbind(array, array)`, but performs as an aggregate function, then combines all the input matrices into one result vertically.|
|`cbind(array, array)`|`array`|`array` is an array of `smallint`, `int`, `bigint`, `real` or `float` data. This function combines the supplied two matrices horizontally. Both matrices needs to have same element data type. If height of matrices are not equivalent, it fills up the padding area by zero.|
|`cbind(array)`|`array`|`array` is an array of `smallint`, `int`, `bigint`, `real` or `float` data. This function is similar to cbind(array, array), but performs as an aggregate function, then combines all the input matrices into one result horizontally.|
|`transpose(array)`|`array`|`array` is an array of `smallint`, `int`, `bigint`, `real` or `float` data. This function makes a transposed matrix that swaps height and width of the supplied matrix.|
|`array_matrix_validation(anyarray)`|`bool`|It validates whether the supplied array (`anyarray`) is adequate for the array-based matrix. It is intended to use for sanity check prior to invocation of PL/CUDA function, or check constraint on domain type definition.|
|`array_matrix_height(array)`|`int`|`array` is an array of either `smallint`, `int`, `bigint`, `real` or `float` data. This function returns the height of the supplied matrix.|
|`array_matrix_width(array)`|`int`|	`array` is an array of either `smallint`, `int`, `bigint`, `real` or `float` data. This function returns the width of the supplied matrix.|
}
